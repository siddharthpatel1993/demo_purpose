<html><u><center><h2>Horizontal Pod Autoscaling</h2></center></u>
<pre><h4>
-> Kubernetes has the possibility to automatically scale pods based on observed CPU utilization, which is horizontal Pod Autoscaling.
-> Scaling can be done only for scalable objects like Controller, Deployment or Replica Set.
-> HPA is implemented as a Kubernetes API resource and a controller.
-> The controller periodically adjust the number of replicas in a replication controller or deployment to match the observed average CPU utilization to the target specified by user.
-> The HPA is implemented as a controlled loop with a period controlled by the controller manager's-horizontal-pod-autoscalar-sync-period flag (Default value of 30 sec).
-> During each period, the controller manager queries the resource utilization against the metrics specified in each horizontal pod autoscalar definition.
-> For per-pod resource metrics (like CPU), the controller fetches the metrics from the resource metrics API for each pod targeted by the Horizontal Pod Autoscaler.
-> Then if a target utilization value is set, the controller calculates the utilization value as a percentage of the equivalent resource request on the containers in each pod.
-> If a target raw-value is set, the raw metric values are used directly. The controller then takes the mean of the utilization or the new value across all targeted pods, and produces a ratio used to scale the number of desired replicas.
-> Cooldown period to wait before another downscale operation can be performed is controlled by --horizontal-pod-autoscaler-downtime-stabilization flag (Default value of 5 min).
-> Metric server needs to be deployed in the cluster to provide metrics via the resource metrics API.

=============================================================

$ wget -O metricserver.yml https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

vi metricserver.yml and under kind: deployment and spec, under secure-port=4443 add - --kubelet-insecure-tls

kubectl apply -f metricserver.yml
kubectl get pods -n kube-system
kubectl logs -f metric_server_pod_name -n kube-system
--------------

vi deployhpa.yml

kind: Deployment
apiVersion: apps/v1
metadata:
   name: mydeploy
spec:
   replicas: 1
   selector:
    matchLabels:
     name: deployment
   template:
     metadata:
       name: testpod8
       labels:
         name: deployment
     spec:
      containers:
        - name: c00
          image: httpd
          ports:
          - containerPort: 80
          resources:
            limits:
              cpu: 500m
            requests:
              cpu: 200m
			  
kubectl apply -f deployhpa
kubectl get all (horizontal pod autoscaler kind should not be there) 
---------------------
$ kubectl autoscale deployment mydeploy --cpu-percent=20 --min=1 --max=10  

kubectl get all (horizontal pod autoscaler kind should be there) 

Go inside pod from another terminal (run apt-get update command) and run watch kubectl get all from first terminal and watch parallel to see increased number of pods.

 

 
</pre></h4>
</html>