<html><u><center><h2>Pod</h2></center></u>
<h4><pre>
-> Kubernetes pods are the foundational unit for all higher Kubernetes objects.
-> A pod hosts one or more containers.
-> It can be created using either a command or a YAML/JSON file.
-> Use kubectl to create pods, view the running ones, modify their configuration, or terminate them. 
-> Kuberbetes will attempt to restart a failing pod by default.
-> If the pod fails to start indefinitely, we can use the kubectl describe command to know what went wrong.
-> Kubectl is the client tool that is used to send API requests to Kubernetes. 
-> Kubectl can be used for building, deleting, viewing, and updating Kubernetes resources. 
-> In fact, kubectl sends API requests to the cluster behind the scenes. 
-> So, technically you can get rid of the tool and issue all your cluster commands through an HTTP client like cURL. 
-> However, it is strongly recommended that you use kubectl; as it is far easier than sending raw HTTP requests.
-> When a pod gets created, it is scheduled to run on a node in your cluster.
-> The pod remains on that node until the process is terminated, the pod object is deleted, the pod is evicted for lack of resources, or the node fails.
-> If a pod is scheduled to a node that fails, or if the scheduling operation itself fails, the pod is deleted.
-> If a node dies, the pod scheduled to that node are scheduled for deletion after a time period.
-> A given pod (UID) is not "rescheduled" to a new node, instead it will be replaced by an identical Pod, with even the same name if desired, but with the new UID.
-> Volume in a POD will exists as long as that POD (with that UID) exist. If that POD is deleted for any reason, volume is also destroyed and created as new on new POD.
-> A controller can create and manage multiple pods, handling replication, roll-out and providing self-healing capabilities.

<h3>Why does Kubernetes use a Pod as the smallest deployable unit, and not a single container?</h3>
-> While it would seem simpler to just deploy a single container directly, there are good reasons to add a layer of abstraction represented by the Pod. 
-> A container is an existing entity, which refers to a specific thing. 
-> That specific thing might be a Docker container, but it might also be a rkt container, or a VM managed by Virtlet. 
-> Each of these has different requirements.
-> What’s more, to manage a container, Kubernetes needs additional information, such as a restart policy, which defines what to do with a container when it terminates, or a 
   liveness probe, which defines an action to detect if a process in a container is still alive from the application’s perspective, such as a web server responding to HTTP 
   requests.
-> Instead of overloading the existing “thing” with additional properties, Kubernetes architects have decided to use a new entity, the Pod, that logically contains (wraps) 
   one or more containers that should be managed as a single entity.

<h3>Why does Kubernetes allow more than one container in a Pod?</h3>
-> Containers in a Pod run on a “logical host”; they use the same network namespace (in other words, the same IP address and port space), and the same IPC namespace. 
-> They can also use shared volumes. 
-> These properties make it possible for these containers to efficiently communicate, ensuring data locality. 
-> Also, Pods enable you to manage several tightly coupled application containers as a single unit.
-> So if an application needs several containers running on the same host, why not just make a single container with everything you need? 
-> Well first, you’re likely to violate the “one process per container” principle. 
-> This is important because with multiple processes in the same container it is harder to troubleshoot the container. 
-> That is because logs from different processes will be mixed together and it is harder manage the processes lifecycle. 
-> For example to take care of “zombie” processes when their parent process dies. 
-> Second, using several containers for an application is simpler, more transparent, and enables decoupling software dependencies. 
-> Also, more granular containers can be reused between teams.


kubectl apply -f pods01.yaml

Viewing Your Pods - kubectl get pods
Which Node Is This Pod Running On? - kubectl get pods -o wide
Describe the pod - kubectl describe po webserver
Output in JSON - kubectl get pods -o json
Executing Commands Against Pods - kubectl exec -it webserver -- /bin/bash
Delete the pod - kubectl delete -f pods01.yaml
Get more details about pod - kubectl get po -o wide
Get logs of Pod - kubectl logs webserver


<h3>Ading a 2nd container to a Pod </h3>
-> In the microservices architecture, each module should live in its own space and communicate with other modules following a set of rules. 
-> But, sometimes we need to deviate a little from this principle. Suppose you have an Nginx web server running and we need to analyze its web logs in real-time. 
-> The logs we need to parse are obtained from GET requests to the web server. The developers created a log watcher application that will do this job and they built a 
   container for it. 
-> In typical conditions, you’d have a pod for Nginx and another for the log watcher. 
-> However, we need to eliminate any network latency so that the watcher can analyze logs the moment they are available. 
-> A solution for this is to place both containers on the same pod.
-> Having both containers on the same pod allows them to communicate through the loopback interface (ifconfig lo) as if they were two processes running on the same host. 
-> They also share the same storage volume.

Let us see how a pod can host more than one container.

$ kubectl apply -f pods02.yaml
$ kubectl get po -o wide
$ kubectl get po,svc,deploy
$ kubectl get po -o wide
How to verify 2 containers are running inside a Pod?
$ kubectl describe po
Since we have two containers in a pod, we will need to use the -c option with kubectl when we need to address a specific container. For example:
$ kubectl exec -it webserver -c webwatcher -- /bin/bash

</pre></h4>
</html>
