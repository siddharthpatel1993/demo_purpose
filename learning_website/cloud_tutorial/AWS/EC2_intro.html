<html><h2><u><center>Elastic Compute Cloud(EC2)</u></center></h2>
<pre><h4>
-> Amazon elastic compute cloud (Amazon EC2) is a web service that provides re-sizable compute capacity in the cloud.
-> Amazon EC2 reduces the time required to obtain and boot new server instances to minutes, allowing you to quickly scale capacity, both up and down as your computing 
   requirements changes.
-> You can use Amazon EC2 to launch as many or as few virtual servers as you need, configure security, networking and manage storage.
-> Amazon EC2 is having two storage options in root volume i.e. EBS and instance state.
-> Pre configured templates are available knows as Amazon Machine Image.
-> By default, when you create an EC2 account with amazon, your account is limited to a maximum of 20 instances per EC2 Region with two default High I/O instances.

 Types of EC2 Instances -
 1. General Purpose (Balanced Memory and CPU)
 2. Compute Optimized (more CPU than RAM)
 3. Memory Optimized (More RAM)
 4. Storage Optimized (Low latency)
 5. Accelerated Computing/ GPU (Graphics Optimized)
 6. High Memory (High RAM, Nitro System)
 7. Previous Generation
 
<mark>Note: Root Volume where you install OS. EBS placed some where outside the server (Network attached Storage), whereas instance state is placed within server (direct attached 
storage).</mark>
 
<h3><u>General Purpose Instances -</u></h3>
-> General Purpose instances provide a Balance of Compute, Memory and Networking Resources, and can be used for variety of workloads.
-> Instances available in four sizes - Nano, Small, Medium and Large. 

<u>There are three series in General Purpose</u>

1. A Series (Medium and Large)
   a. A1

2. M Series (Large)
   a. M4
   b. M5
   c. M5a
   d. M5ad
   e. M5d
   
3. T Series (Nano, Small, Medium and Large)
   a. T2
   b. T3
   c. T3a
   
<u>A1 - Instances</u>
A1-instances are ideally suited for scale-out workloads that are supported by the ARM Ecosystem.

These instance are well-suited for the following application -
1. WebServer
2. Containerized micro services
3. Caching Fleets
4. Distributed data stores
5. Application that requires ARM instruction set.    

Note:-
1. Microservice is a distinct method to developing software systems that tries to focus on building single-function modules with well defined interfaces and operations.
2. Cache is a high-speed data storage layer which stores a subset of data, typically transient in nature, so that future request for that data are served up faster.

<u>M4, M5, M5a, M5ad, M5d instances</u>

1. M4 Instance

-> The new M4 instances features a custom Intel Xeon E5-2676 v3 Haswell processor optimzed specifically for EC2.

vCPU -> 2 to 40 (Max)
RAM -> 8GB to 160GB (Max)
Instance Storage -> EBS Only 

2. M5, M5a, M5ad, M5d Instances

-> These instances provide an ideal cloud infrastructure, offering a Balance of compute, memory and networking resources for broad range of applications.
-> Used in Gaming Server, WebServer, small and Medium databases
-> M4, M5, M5a is mostly used. 
   
vCPU -> 2 to 96 (Max)
RAM -> 8 to 385 (Max)
Instance Storage -> EMS and NVMe SSD   

3. T2, T3 and T3a Instances

-> These instances provide a baseline level of CPU performance with the ability to burst to a higher level when required by your workload.
-> An unlimited instances can sustain high CPU performance for any period of time whenever required.

Used for -
i. Website and WebApp
ii. Code Repositories
iii. Development, build, test
iv. Microservices

VCPU -> 2 to 8 GB
RAM -> 0.5 to 32 GB

<h3><u>Compute Optimized -</u></h3>
-> Compute Optimized Instances are ideal for compute-bound applications that benefit from high performance processors.
-> It has only C series
-> There are three types available -> C4, C5, C5n {C3 -> Previous Instance}

C4 => C4 instances are optimzed for compute intensive workloads and deliver very cost effective high performance at a low price per compute ratio.

VCPU -> 2 to 36
Storage -> EBS Only
RAM -> 3.75 to 60 GB
Network Bandwidth -> 10 Gbps

Use Cases - WebServer, Batch Processing, MMO Gaming, Video Encoding

C5 instances -> C5 instances are optimized for compute intensive workloads and delivers very cost effective high performance at a low price per compute ratio.
-> Powered by AWS Nirto system

VCPU -> 2 to 72
Storage -> EBS Only & NVMe SSD
RAM -> 3.75 to 192 GB
Network Bandwidth -> Upto 25 Gbps

Use cases -> High performance web servers, Gaming, Video Encoding

Note:
1. C5 support max. 25 EBS volumes
2. C5 uses Elastic Network Adaptor
3. C5 uses new EC2 Hypervisor.

<h3><u>Memory Optimized -</u></h3>
-> Memory Optimized instances are designed to deliver fast performance for workloads that process large data sets in memory.
-> It has three series - R series, X series and Z series
-> If you need more RAM and has to work on big databases then you can opt for X series because it has very high RAM and then Z series and R series.

R4, R5, R5ad and R5d

-> High performance, Relational (MySQL) and NoSQL (MangoDB, Cassandra) databases.
-> Distributed web scale cache stores that provides in-memory caching of key value type data.
-> Used in financial services, Hadoop

vCPU - 2 to 96
RAM - 16 to 768 Gbps
Instance Storage - EBS only & NVMe SSD

X1, X1e Instances

-> Well suited for High performance database, memory intensive enterprise application, Relational database workload, SAP HANA
-> Electronic Design Automation

vCPU - 4 to 128
RAM - 122 to 3904 Gbps
Instance Storage - SSD

Z1d Instance

-> High frequency Z1d delivers a sustained all core frequency of upto 4.0 GHz, the fastest of any cloud instances.
-> AWS Nitro System, Xeon Processor, upto 1.8 TB of instances storage

vCPU - 2 to 48
RAM - 16 to 384 GB 
Storage - NVM SSD

Use cases - Electronic Design, Automation and certain databases workloads with high per-core licensing cost.

<h3><u>Storage Optimized Instances-</u></h3> 

-> Storage optimized instances are designed for workloads that require high, sequential Read and Write access to very large data sets on local storage.
-> They are optimized to deliver tens of thousands of low latency, random I/O operations per second (IOPS) to application.

D2 instances

Well suited for the following -
1. Massive Parallel Processing (MPP) data warehouse
2. Map reduce and Hadoop distributed computing
3. Log or data processing app

vCPU - 40 to 36
RAM - 30.5 to 244 GB
Storage - SSD

H1 Instances

-> This family features upto 16 TB of HDD Based local storage, high disk throughput and balance of compute and memory.
-> Well suited for App requiring sequential access to large amounts of data on direct-attached instance storage.
-> Application that requires high throughput access to large quantities of data.

vCPU - 8 to 64
RAM - 32 to 256 GB
Storage - HDD

I3 to I3en Instances

Well suited for -
1. High frequency online transaction processing system (OLTP)
2. Relational Databases
3. NoSQL Databases
4. Distributed File System
5. Data Warehousing application

vCPU - 2 to 96
RAM - 16 to 768 GB
Local Storage - NVMe SSD
Network performance - 25 Gbps to 100 Gbps 

Sequential Throughput
Read - 16 GB/s
Write - 6.4 GB/s (I3)
        8 GB/s  (I3en)

<h3><u>5. Accelerated Computing Instances</u></h3>

-> Accelerated computing instances families uses Hardware accelerators, or co-processor to perform some functions such as floating point number calculation,
   graphics processing or data pattern matching more efficiently than is possible in software running on CPUs.
-> It has three series (P,G,F series) 

<u>F1 instances -</u>

-> F1 instances offers customizable Hardware acceleration with Field Programmable Gate arrays (FPGA)
-> Each FPGA contains 2.5 million logic elements and 6800 DSP engines.
-> Designed to accelerate computationally intensive algorithms, such as data flow or high parallel operations.
-> F1 provides Local NVM SSD storage.

vCPU - 8 to 64
FPGA - 1 to 8
RAM - 122 to 976 GB
Storage - NVMe SSD

Used in - Genomics Research, Financial analytics, Real time Video Processing and Big data search.  

<u>P2 and P3 instances -</u>

-> It uses NVIDIA Tesla GPUs.
-> Provide high Bandwidth Networking.
-> Upto 32 GB of memory per GPUs which makes them ideal for deep Learning and computational Fluid Dynamics.

P2 instance
vCPU - 4 to 64
GPU - 1 to 16
RAM - 61 to 732 GB
GPU RAM - 12 to 192 GB
Network BW - 25 Gbps

P3 instance
vCPU - 8 to 96
GPU - 1 to 8
RAM - 61 - 768 GB
Storage - SSD and EBS

Used in - Machine Learning, Databases, Seismic Analysis, Genomics, Molecular Modeling, AI, Deep Learning

Note: P3 support CUDA9 and OpenCL APIs.
      P2 support CUDA8 and OpenCL 1.2

<u>G2 and G3 instances -</u>

-> Optimized for Graphics Intensive application
-> Well suited for app like 3D Visualization
-> G3 Instances use NVIDIA Tesla M60 GPU and provide a cost effective, high performace platform for Graphics applications.

vCPU - 4 to 64
GPU - 1 to 4	
RAM - 30.5 to 488 GB
GPU memory -  8 to 32 GB
Network Performance - 25 Gbps

Used in - Video creation services, 3D visualization, streaming graphics-intensive application.  

<h3><u>6. High Memory Instances</u></h3>

-> High Memory Instances are build to run large-in-memory databases, including production developments of SAP HANA in the cloud.
-> It has just one U series (U6, U9, U12)

<u>Features :-</u>
1. Latest generation Intel Xeon Pentium 8176M processor.
2. 6,9,12 TB of instance Memory, the largest of any EC2 instance.
3. Powered by the AWS Nitro System, a combination of dedicated Hardware and Lightweight Hypervisor.
4. Bare Metal performance with direct access to host Hardware.
5. EBS optimized by default at no additional cost (Model no - u-6tb1.metal, u-9tb1.metal & u-12tb1.metal)
6. Network Performance - 25 Gbps, Dedicated EBS Bandwidth - 14 Gbps
7. Each instance offer 448 logical processor

<u>Note:</u> 
1. High Memory Instances are bare metal instances and do not run on Hypervisor.
2. Only available under dedicated host purchasing category (For 3 yr. term)
3. O.S. directly on hardware. 

<h3><u>7. Previous Generation Instances</u></h3>
T1, M1, C1, CC2, M2, CR1, CG2, i2, HS1, M3, C3 and R3
</h4></pre>
</html>
